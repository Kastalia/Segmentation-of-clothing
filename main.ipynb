{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import ctc_loss, log_softmax\n",
    "from torchvision.transforms import Compose\n",
    "import editdistance\n",
    "\n",
    "# segmentation\n",
    "from segmentation.unet import UNet\n",
    "from segmentation.maskrcnn import maskrcnn_resnet50_fpn\n",
    "from segmentation.dataset import DetectionDataset\n",
    "import segmentation.transform\n",
    "import segmentation.routine\n",
    "import segmentation_models_pytorch as smp\n",
    "# the proper way to do this is relative import, one more nested package and main.py outside the package\n",
    "# will sort this out\n",
    "#sys.path.insert(0, os.path.abspath((os.path.dirname(__file__)) + '/../'))\n",
    "\n",
    "\n",
    "from utils import get_logger, dice_coeff, dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config hyper parametrs\n",
    "#data_path = \"C:\\\\Users\\\\Lisen\\\\Desktop\\\\CV\\\\data\\\\\" #path to the data\n",
    "#data_path = \"//home//mayer//LocalRepository//JupyterProjects//MADE_2019_cv//02_CarPlatesOCR//data//\" \n",
    "epochs = 13 #number of epochs\n",
    "batch_size = 16 #batch size\n",
    "image_size = 256 #input image size\n",
    "lr = 1e-3 #learning rate\n",
    "weight_decay = 5e-4 #weight decay\n",
    "lr_step = 3 #learning rate step\n",
    "lr_gamma = 0.3 #learning rate gamma\n",
    "model = UNet()\n",
    "#model = smp.Unet('resnext50_32x4d', encoder_weights='imagenet',classes=13)\n",
    "#model = smp.FPN(encoder_name='resnext50_32x4d', encoder_weights='imagenet',classes=2)\n",
    "#model = maskrcnn_resnet50_fpn()\n",
    "weight_bce = 0.5 #weight BCE loss\n",
    "load = False #load file model\n",
    "val_split = 0.8 #train/val split\n",
    "output_dir = \"temp\\\\\"#dir to save log and models\n",
    "#output_dir = \"//home//mayer//LocalRepository//JupyterProjects//MADE_2019_cv//02_CarPlatesOCR//temp//\"\n",
    "part = 1 # config which part of train dataset use\n",
    "#segmentationFile =  'C:\\\\Users\\\\Lisen\\\\Desktop\\\\CV\\\\dataset\\\\segmentation.json'\n",
    "segmentationFile = \"/home/mayer/LocalRepository/JupyterProjects/DeepFashion2/dataset/segmentation.json\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# TODO: to use move novel arch or/and more lightweight blocks (mobilenet) to enlarge the batch_size\n",
    "# TODO: img_size=256 is rather mediocre, try to optimize network for at least 512\n",
    "if load:\n",
    "    model.load_state_dict(torch.load(load))\n",
    "model = model.to(device)\n",
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-25 18:06:13 Start training with params:\n",
      "2020-07-25 18:06:13 Argument epochs: 13\n",
      "2020-07-25 18:06:13 Argument batch_size: 16\n",
      "2020-07-25 18:06:13 Argument image_size: 256\n",
      "2020-07-25 18:06:13 Argument lr: 0.001\n",
      "2020-07-25 18:06:13 Argument weight_decay: 0.0005\n",
      "2020-07-25 18:06:13 Argument lr_step: 3\n",
      "2020-07-25 18:06:13 Argument lr_gamma: 0.3\n",
      "2020-07-25 18:06:13 Argument weight_bce: 0.5\n",
      "2020-07-25 18:06:13 Argument load: False\n",
      "2020-07-25 18:06:13 Argument val_split: 0.8\n",
      "2020-07-25 18:06:13 Argument output_dir: 'temp\\\\'\n",
      "2020-07-25 18:06:13 Argument segmentationFile: '/home/mayer/LocalRepository/JupyterProjects/DeepFashion2/dataset/segmentation.json'\n",
      "2020-07-25 18:06:13 Model type: UNet\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "logger = get_logger(os.path.join(output_dir, 'segmentation_train.log'))\n",
    "logger.info('Start training with params:')\n",
    "logger.info(\"Argument %s: %r\", \"epochs\", epochs)\n",
    "logger.info(\"Argument %s: %r\", \"batch_size\", batch_size)\n",
    "logger.info(\"Argument %s: %r\", \"image_size\",image_size )\n",
    "logger.info(\"Argument %s: %r\", \"lr\", lr)\n",
    "logger.info(\"Argument %s: %r\", \"weight_decay\",weight_decay )\n",
    "logger.info(\"Argument %s: %r\", \"lr_step\", lr_step)\n",
    "logger.info(\"Argument %s: %r\", \"lr_gamma\",lr_gamma )\n",
    "logger.info(\"Argument %s: %r\", \"weight_bce\", weight_bce)\n",
    "logger.info(\"Argument %s: %r\", \"load\", load)\n",
    "logger.info(\"Argument %s: %r\", \"val_split\", val_split)\n",
    "logger.info(\"Argument %s: %r\", \"output_dir\", output_dir)\n",
    "logger.info(\"Argument %s: %r\", \"segmentationFile\", segmentationFile)\n",
    "logger.info('Model type: {}'.format(model.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-25 18:06:14 Length of train/val=6836/1709\n",
      "2020-07-25 18:06:14 Number of batches of train/val=427/107\n",
      "2020-07-25 18:06:14 Starting epoch 1/13.\n",
      "/home/mayer/packages/anaconda3/envs/dsjune20/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/mayer/packages/anaconda3/envs/dsjune20/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/427 [00:00<?, ?it/s]/home/mayer/packages/anaconda3/envs/dsjune20/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "mean loss: 1.3538:   1%|          | 5/427 [01:48<2:28:40, 21.14s/it]2020-07-25 18:08:14 Saved interrupt\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayer/packages/anaconda3/envs/dsjune20/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# TODO: loss experimentation, fight class imbalance, there're many ways you can tackle this challenge\n",
    "criterion = lambda x, y: (weight_bce * nn.BCELoss()(x, y), (1. - weight_bce) * dice_loss(x, y))\n",
    "# TODO: you can always try on plateau scheduler as a default option\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=lr_gamma) \\\n",
    "    if lr_step > 0 else None\n",
    "\n",
    "# dataset\n",
    "# TODO: to work on transformations a lot, look at albumentations package for inspiration\n",
    "train_transforms = segmentation.transform.Compose([\n",
    "    segmentation.transform.Crop(min_size=1 - 1 / 3., min_ratio=1.0, max_ratio=1.0, p=0.5),\n",
    "    segmentation.transform.Flip(p=0.05),\n",
    "    segmentation.transform.Pad(max_size=0.6, p=0.25),\n",
    "    segmentation.transform.Resize(size=(image_size, image_size), keep_aspect=True)\n",
    "])\n",
    "# TODO: don't forget to work class imbalance and data cleansing\n",
    "val_transforms = segmentation.transform.Resize(size=(image_size, image_size))\n",
    "\n",
    "train_dataset = DetectionDataset(segmentationFile, transforms=train_transforms, part=part)\n",
    "val_dataset = DetectionDataset(None, transforms=val_transforms, part=part)\n",
    "\n",
    "# split dataset into train/val, don't try to do this at home ;)\n",
    "train_size = int(len(train_dataset) * val_split)\n",
    "val_dataset.image_names = train_dataset.image_names[train_size:]\n",
    "val_dataset.mask_names = train_dataset.mask_names[train_size:]\n",
    "train_dataset.image_names = train_dataset.image_names[:train_size]\n",
    "train_dataset.mask_names = train_dataset.mask_names[:train_size]\n",
    "\n",
    "# TODO: always work with the data: cleaning, sampling\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8,\n",
    "                              shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4,\n",
    "                            shuffle=False, drop_last=False)\n",
    "logger.info('Length of train/val=%d/%d', len(train_dataset), len(val_dataset))\n",
    "logger.info('Number of batches of train/val=%d/%d', len(train_dataloader), len(val_dataloader))\n",
    "\n",
    "try:\n",
    "    segmentation.routine.train(model, optimizer, criterion, scheduler, epochs, train_dataloader, val_dataloader, saveto=output_dir,\n",
    "          device=device, logger=logger, show_plots=True)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.info('Saved interrupt')\n",
    "    sys.exit(0)\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
